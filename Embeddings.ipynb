{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/embedding\n",
    "\n",
    "Embeddings are important for input to machine learning. Classifiers, and neural networks more generally, work on vectors of real numbers. They train best on dense vectors, where all values contribute to define an object. However, many important inputs to machine learning, such as words of text, do not have a natural vector representation. Embedding functions are the standard and effective way to transform such discrete input objects into useful continuous vectors.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "```python\n",
    "blue:  (red, 47.6°), (yellow, 51.9°), (purple, 52.4°)\n",
    "blues:  (jazz, 53.3°), (folk, 59.1°), (bluegrass, 60.6°)\n",
    "orange:  (yellow, 53.5°), (colored, 58.0°), (bright, 59.9°)\n",
    "oranges:  (apples, 45.3°), (lemons, 48.3°), (mangoes, 50.4°)\n",
    "```\n",
    "\n",
    "### FAQ:\n",
    "\n",
    "#### Is \"embedding\" an action or a thing? Both. \n",
    "People talk about embedding words in a vector space (action) and about producing word embeddings (things). Common to both is the notion of embedding as a mapping from discrete objects to vectors. Creating or applying that mapping is an action, but the mapping itself is a thing.\n",
    "\n",
    "#### Are embeddings high-dimensional or low-dimensional? It depends. \n",
    "A 300-dimensional vector space of words and phrases, for instance, is often called low-dimensional (and dense) when compared to the millions of words and phrases it can contain. But mathematically it is high-dimensional, displaying many properties that are dramatically different from what our human intuition has learned about 2- and 3-dimensional spaces.\n",
    "\n",
    "#### Is an embedding the same as an embedding layer? No. \n",
    "An embedding layer is a part of neural network, but an embedding is a more general concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Dataset\n",
    "\n",
    "Data available from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "\n",
    "FAST AI reference: https://github.com/fastai/fastai/blob/master/fastai/column_data.py\n",
    "\n",
    "FAST AI lesson: https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = '/Users/timlee/data/movielens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    ratings = pd.read_csv(path+'ratings.csv')\n",
    "    movies = pd.read_csv(path+'movies.csv')\n",
    "    return ratings, movies\n",
    "\n",
    "ratings, movies = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a custom dataset and dataloader in `pytorch` using the `dataset`, and `dataloader` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class movielens_ds(Dataset):\n",
    "    def __init__(self, cat_vars, cont_vars, target):\n",
    "        n = len(target)\n",
    "        self.cat_vars = np.stack(cat_vars, 1).astype(np.int64) if cat_vars else np.zeros((n,1))\n",
    "        self.cont_vars = np.stack(cont_vars,1).astype(np.int64) if cont_vars else np.zero((n,1))\n",
    "        self.y = np.zeros((n,1)) if y is None else y[:,None]\n",
    "    \n",
    "    def __len__(self): return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "    \n",
    "    def import_df(cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
